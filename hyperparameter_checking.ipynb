{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1720a8a7-2f3d-4bc8-bf96-00c9b4d70213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/theo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/theo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/9z/yfn644md6173n9mhgk_zyv2h0000gn/T/ipykernel_2008/3594020688.py:18: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"train_set.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: Index(['Unnamed: 0', 'id', 'domain', 'type', 'url', 'content', 'scraped_at',\n",
      "       'inserted_at', 'updated_at', 'title', 'authors', 'keywords',\n",
      "       'meta_keywords', 'meta_description', 'tags', 'summary', 'source'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/theo/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/theo/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "2018-02-10 13:43:39.521661       0.00      0.00      0.00         1\n",
      "                      bias       0.74      0.68      0.71    106564\n",
      "                 clickbait       0.71      0.37      0.49     21897\n",
      "                conspiracy       0.71      0.65      0.68     77782\n",
      "                      fake       0.77      0.73      0.75     83963\n",
      "                      hate       0.79      0.59      0.67      7026\n",
      "                   junksci       0.73      0.51      0.60     11280\n",
      "                 political       0.63      0.79      0.70    155644\n",
      "                  reliable       0.83      0.91      0.87    174833\n",
      "                     rumor       0.87      0.88      0.87     45138\n",
      "                    satire       0.63      0.32      0.43     10475\n",
      "                   unknown       0.70      0.45      0.54     34780\n",
      "                unreliable       0.94      0.78      0.85     28285\n",
      "\n",
      "                  accuracy                           0.75    757668\n",
      "                 macro avg       0.70      0.59      0.63    757668\n",
      "              weighted avg       0.75      0.75      0.74    757668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theo/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "2018-02-10 13:43:39.521661       0.00      0.00      0.00         1\n",
      "                      bias       0.77      0.70      0.73    106564\n",
      "                 clickbait       0.72      0.45      0.55     21897\n",
      "                conspiracy       0.73      0.67      0.70     77782\n",
      "                      fake       0.78      0.75      0.77     83963\n",
      "                      hate       0.87      0.70      0.78      7026\n",
      "                   junksci       0.79      0.65      0.71     11280\n",
      "                 political       0.65      0.80      0.72    155644\n",
      "                  reliable       0.86      0.92      0.88    174833\n",
      "                     rumor       0.89      0.91      0.90     45138\n",
      "                    satire       0.71      0.49      0.58     10475\n",
      "                   unknown       0.72      0.51      0.59     34780\n",
      "                unreliable       0.95      0.82      0.88     28285\n",
      "\n",
      "                  accuracy                           0.77    757668\n",
      "                 macro avg       0.73      0.64      0.68    757668\n",
      "              weighted avg       0.77      0.77      0.77    757668\n",
      "\n",
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bias       0.74      0.67      0.70     13336\n",
      "   clickbait       0.62      0.39      0.48      2763\n",
      "  conspiracy       0.70      0.64      0.67      9857\n",
      "        fake       0.75      0.71      0.73     10468\n",
      "        hate       0.68      0.58      0.63       897\n",
      "     junksci       0.63      0.52      0.57      1388\n",
      "   political       0.63      0.77      0.69     19341\n",
      "    reliable       0.84      0.90      0.87     21906\n",
      "       rumor       0.86      0.87      0.87      5618\n",
      "      satire       0.58      0.41      0.48      1351\n",
      "     unknown       0.62      0.45      0.52      4306\n",
      "  unreliable       0.89      0.79      0.83      3530\n",
      "\n",
      "    accuracy                           0.74     94761\n",
      "   macro avg       0.71      0.64      0.67     94761\n",
      "weighted avg       0.74      0.74      0.73     94761\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bias       0.73      0.67      0.70     13332\n",
      "   clickbait       0.61      0.37      0.46      2752\n",
      "  conspiracy       0.70      0.64      0.67      9675\n",
      "        fake       0.75      0.71      0.73     10452\n",
      "        hate       0.63      0.52      0.57       856\n",
      "     junksci       0.65      0.53      0.59      1372\n",
      "   political       0.63      0.76      0.69     19533\n",
      "    reliable       0.84      0.90      0.87     21825\n",
      "       rumor       0.86      0.88      0.87      5689\n",
      "      satire       0.54      0.38      0.45      1334\n",
      "     unknown       0.62      0.45      0.53      4448\n",
      "  unreliable       0.89      0.78      0.83      3517\n",
      "\n",
      "    accuracy                           0.73     94785\n",
      "   macro avg       0.70      0.63      0.66     94785\n",
      "weighted avg       0.73      0.73      0.73     94785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv(\"train_set.csv\")\n",
    "\n",
    "# Print dataset columns to check available labels\n",
    "print(\"Dataset Columns:\", data.columns)\n",
    "\n",
    "# Assuming the correct label column is 'type' based on typical datasets\n",
    "label_column = 'type' if 'type' in data.columns else 'label'\n",
    "\n",
    "# Drop rows with NaN values in label column\n",
    "data = data.dropna(subset=[label_column])\n",
    "\n",
    "# Ensure text data is preprocessed\n",
    "data['processed_text'] = data['content'].fillna('')\n",
    "\n",
    "# Feature Extraction (Bag of Words & TF-IDF)\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train_vec = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_vec, data[label_column])\n",
    "y_pred = log_reg.predict(X_train_vec)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(data[label_column], y_pred))\n",
    "\n",
    "# Load validation and test datasets\n",
    "val_data = pd.read_csv(\"val_set.csv\", dtype=str)\n",
    "test_data = pd.read_csv(\"test_set.csv\", dtype=str)\n",
    "\n",
    "# Apply the same processing to validation and test datasets\n",
    "for dataset_name in [\"val_set.csv\", \"test_set.csv\"]:\n",
    "    dataset = pd.read_csv(dataset_name, dtype=str)\n",
    "    dataset = dataset.dropna(subset=[label_column])\n",
    "    dataset[label_column] = dataset[label_column].astype(str)\n",
    "    dataset['processed_text'] = dataset['content'].fillna('')\n",
    "    \n",
    "    if dataset_name == \"val_set.csv\":\n",
    "        val_data = dataset\n",
    "        X_val_vec = vectorizer.transform(val_data['processed_text'])\n",
    "    else:\n",
    "        test_data = dataset\n",
    "        X_test_vec = vectorizer.transform(test_data['processed_text'])\n",
    "\n",
    "# Logistic Regression Model with increased max_iter\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_vec, data[label_column])\n",
    "y_pred = log_reg.predict(X_train_vec)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(data[label_column], y_pred, zero_division=0))\n",
    "\n",
    "# Evaluate Logistic Regression Model on validation and test sets\n",
    "y_val_pred = log_reg.predict(X_val_vec)\n",
    "y_test_pred = log_reg.predict(X_test_vec)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(val_data[label_column], y_val_pred, zero_division=0))\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(classification_report(test_data[label_column], y_test_pred, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c91675-ab65-455c-b40b-d5dcdb7e0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import swifter  # Faster parallel apply\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load stopwords once to improve performance\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses text data to improve model performance.\n",
    "    - Converts to lowercase\n",
    "    - Removes non-word characters (punctuation, symbols)\n",
    "    - Tokenizes text into words\n",
    "    - Removes common stopwords\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    words = word_tokenize(text)  # Tokenize into words\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Load and process training dataset\n",
    "data = pd.read_csv(\"train_set.csv\", dtype=str)\n",
    "label_column = 'type' if 'type' in data.columns else 'label'  # Identify the label column\n",
    "data = data.dropna(subset=[label_column])  # Remove rows with missing labels\n",
    "data[label_column] = data[label_column].astype(str)  # Ensure labels are strings\n",
    "data['processed_text'] = data['content'].fillna('').swifter.apply(preprocess_text)  # Apply text preprocessing\n",
    "\n",
    "# Load and process validation dataset\n",
    "val_data = pd.read_csv(\"val_set.csv\", dtype=str)\n",
    "val_data = val_data.dropna(subset=[label_column])\n",
    "val_data[label_column] = val_data[label_column].astype(str)\n",
    "val_data['processed_text'] = val_data['content'].fillna('').swifter.apply(preprocess_text)\n",
    "\n",
    "# Load and process test dataset\n",
    "test_data = pd.read_csv(\"test_set.csv\", dtype=str)\n",
    "test_data = test_data.dropna(subset=[label_column])\n",
    "test_data[label_column] = test_data[label_column].astype(str)\n",
    "test_data['processed_text'] = test_data['content'].fillna('').swifter.apply(preprocess_text)\n",
    "\n",
    "# Feature Extraction using TF-IDF (Increasing max features and adding n-grams)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data['processed_text'])\n",
    "X_val_tfidf = tfidf_vectorizer.transform(val_data['processed_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['processed_text'])\n",
    "\n",
    "# Define Logistic Regression Model\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Define Hyperparameter Grid for Optimization\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [300, 500, 1000]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(log_reg, param_grid, scoring='f1_weighted', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, data[label_column])\n",
    "\n",
    "# Best Model after Hyperparameter Tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Generate Predictions\n",
    "y_val_pred = best_model.predict(X_val_tfidf)\n",
    "y_test_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(val_data[label_column], y_val_pred, zero_division=0))\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(classification_report(test_data[label_column], y_test_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
